y = c(429, 430, 430, 431, 436, 437, 440, 441, 445, 446, 447)
y.mean = mean(y)
y.sd = sd(y)
par(mfrow = c(1,2))
hist(y)
qqnorm(y)
y
par(mfrow = c(1,3))
boxplot(x)
hist(x)
qqnorm(x)
par(mfrow = c(1,2))
boxplot(x)
boxplot(y)
par(mfrow = c(1,2))
hist(y)
qqnorm(y)
setwd("/home/ravschoo/Documents/Desktop/TMATH390/TMATH390_SP17")
list.files()
library(readr)
KWayMergeData_r <- read_csv("/home/ravschoo/Documents/Desktop/TMATH390/KWayMergeData_r.csv")
x = KWayMergeData_r$`k = 2`
y = KWayMergeData_r$`k = 3`
fivenum(x)
fivenum(y)
par(mfrow = c(1, 3))
boxplot(x, ylab = "Time in milliseconds for k = 2")
boxplot(y, ylab = "Time in milliseconds for k = 3")
plot(x, y, xlab = "Time in millisecond for k = 2", ylab = "Time in milliseconds for k = 3")
sar <- read_tsv(activity.tsv)
sar <- read_tsv(activity.tsv)
setwd("/home/ravschoo/ResourceContention/IaaSCloudResourceContention/modeldata/m5d")
#Clear workspace
rm(list=ls())
library(randomForest)
library(rpart)
setwd("/home/ravschoo/ResourceContention/IaaSCloudResourceContention/modeldata/m5d")
#Clear workspace
rm(list=ls())
#I need to take it each benchmarks data set
ycruncher <- read.table("./ycruncher_standardized.csv", sep=",", header=TRUE)
sysbench <- read.table("./sysbench_standardized.csv", sep=",", header=TRUE)
pgbench <- read.table("./pgbench_standardized.csv", sep=",", header=TRUE)
iperf <- read.table("./iperf_standardized.csv", sep=",", header=TRUE)
#Take just 3 observations for each set and vid
new_sysbench <- data.frame(sysbench=vector(), setId=vector(), vmId=vector())
for (setid in 0:47) {
for (vmid in 1:48) {
#for each set and vm combination we need 3 observations
result <- sysbench[(sysbench$setId == setid & sysbench$vmId == vmid), ][1:3, ]
result <- na.omit(result)
result$sysbench <- as.numeric(gsub("s", "", unlist(result$sysbench)))
new_sysbench <- rbind(new_sysbench, result)
}
}
new_ycruncher <- data.frame(ycruncher=vector(), setId=vector(), vmId=vector())
for (setid in 0:47) {
for (vmid in 1:48) {
#for each set and vm combination we need 3 observations
result <- ycruncher[(ycruncher$setId == setid & ycruncher$vmId == vmid), ][1:3, ]
result <- na.omit(result)
new_ycruncher <- rbind(new_ycruncher, result)
}
}
new_iperf <- data.frame(iperf=vector(), setId=vector(), vmId=vector())
for (setid in 0:47) {
for (vmid in 1:48) {
#for each set and vm combination we need 3 observations
result <- iperf[(iperf$setId == setid & iperf$vmId == vmid), ][1:3, ]
result <- na.omit(result)
new_iperf <- rbind(new_iperf, result)
}
}
View(new_iperf)
View(new_sysbench)
new_iperf <- data.frame(iperf=vector(), setId=vector(), vmId=vector())
for (setid in 1:48) {
for (vmid in 1:48) {
#for each set and vm combination we need 3 observations
result <- iperf[(iperf$setId == setid & iperf$vmId == vmid), ][1:3, ]
result <- na.omit(result)
new_iperf <- rbind(new_iperf, result)
}
}
new_sysbench$setId <- new_sysbench$setId * -1 + 48
new_sysbench <- new_sysbench[order(new_sysbench$setId), ]
print(head(new_sysbench))
print(head(new_iperf))
print(head(new_ycruncher))
new_ycruncher$setId <- new_ycruncher$setId * -1 + 48
new_ycruncher <- new_ycruncher[order(new_ycruncher$setId), ]
print(head(new_ycruncher))
pgbench$setId <- pgbench$setId * -1 + 48
pgbench <- pgbench[order(pgbench$setId), ]
print(head(pgbench))
#Now fix the vmids
pgbench$vmId <- new_iperf$vmId
new_sysbench$vmId <- new_iperf$vmId
new_ycruncher$vmId <- new_iperf$vmId
#Notice that as of now the vmids are not in the right order.
#Should start with 1 and go consecutively, will fix later.
print(head(new_sysbench))
print(head(new_ycruncher))
print(head(pgbench))
#All data sets should have same dimensions
print(dim(new_iperf))
print(dim(pgbench))
print(dim(new_sysbench))
print(dim(new_ycruncher))
#Put all data into a dataframe
globalMerged = data.frame()
for (set in 1:48) {
for (vm in 1:set) {
a = new_iperf[new_iperf$setId == set & new_iperf$vmId == vm,]
b = new_sysbench[new_sysbench$setId == set & new_sysbench$vmId == vm,]
c = new_ycruncher[new_ycruncher$setId == set & new_ycruncher$vmId == vm,]
d = pgbench[pgbench$setId == set & pgbench$vmId == vm,]
merged = cbind(a["i_perf"],b["sysbench"],c["yCruncher"],d["pgbench"],rep.int(set, 3), rep.int(vm, 3))
globalMerged = rbind(globalMerged, merged)
}
}
View(globalMerged)
#write it out as merged.csv.
write.csv(globalMerged,"./merged.csv",row.names=FALSE, col.names=FALSE)
setwd("/home/ravschoo/ResourceContention/IaaSCloudResourceContention/modeldata/m5d")
#Clear workspace
rm(list=ls())
library(randomForest)
library(rpart)
wholeSet = read.csv("./merged.csv")
str(wholeSet)
# Loading the dplyr package
library(dplyr)
# Using sample_frac to create 70 - 30 slipt into test and train
train <- sample_frac(wholeSet, 0.9)
sample_id <- as.numeric(rownames(train)) # rownames() returns character so as.numeric
test <- wholeSet[-sample_id,]
View(wholeSet)
wholeSet = read.csv("./merged.csv")
str(wholeSet)
# Using sample_frac to create 70 - 30 slipt into test and train
train <- sample_frac(wholeSet, 0.9)
sample_id <- as.numeric(rownames(train)) # rownames() returns character so as.numeric
test <- wholeSet[-sample_id,]
formula = set~iperf+sysbench+ycruncher+pgbench
modelRandomForest <- randomForest(
formula,
data=train)
wholeSet = read.csv("./merged.csv")
# Using sample_frac to create 70 - 30 slipt into test and train
train <- sample_frac(wholeSet, 0.9)
sample_id <- as.numeric(rownames(train)) # rownames() returns character so as.numeric
test <- wholeSet[-sample_id,]
formula = set~iperf+sysbench+ycruncher+pgbench
modelRandomForest <- randomForest(
formula,
data=train)
print(modelRandomForest)
setwd("/home/ravschoo/ResourceContention/IaaSCloudResourceContention/modeldata/m5d")
#Clear workspace
rm(list=ls())
#I need to take it each benchmarks data set
ycruncher <- read.table("./ycruncher_standardized.csv", sep=",", header=TRUE)
sysbench <- read.table("./sysbench_standardized.csv", sep=",", header=TRUE)
pgbench <- read.table("./pgbench_standardized.csv", sep=",", header=TRUE)
iperf <- read.table("./iperf_standardized.csv", sep=",", header=TRUE)
#Take just 3 observations for each set and vid
new_sysbench <- data.frame(sysbench=vector(), setId=vector(), vmId=vector())
for (setid in 0:47) {
for (vmid in 1:48) {
#for each set and vm combination we need 3 observations
result <- sysbench[(sysbench$setId == setid & sysbench$vmId == vmid), ][1:3, ]
result <- na.omit(result)
result$sysbench <- as.numeric(gsub("s", "", unlist(result$sysbench)))
new_sysbench <- rbind(new_sysbench, result)
}
}
new_ycruncher <- data.frame(ycruncher=vector(), setId=vector(), vmId=vector())
for (setid in 0:47) {
for (vmid in 1:48) {
#for each set and vm combination we need 3 observations
result <- ycruncher[(ycruncher$setId == setid & ycruncher$vmId == vmid), ][1:3, ]
result <- na.omit(result)
new_ycruncher <- rbind(new_ycruncher, result)
}
}
new_iperf <- data.frame(iperf=vector(), setId=vector(), vmId=vector())
for (setid in 1:48) {
for (vmid in 1:48) {
#for each set and vm combination we need 3 observations
result <- iperf[(iperf$setId == setid & iperf$vmId == vmid), ][1:3, ]
result <- na.omit(result)
new_iperf <- rbind(new_iperf, result)
}
}
View(new_sysbench)
View(new_sysbench)
new_sysbench$setId <- new_sysbench$setId * -1 + 48
new_sysbench <- new_sysbench[order(new_sysbench$setId), ]
#Notice that as of now the vmids are not in the right order.
#Should start with 1 and go consecutively, will fix later.
print(head(new_sysbench))
#This data set looks good already
print(head(new_iperf))
View(new_ycruncher)
new_ycruncher$setId <- new_ycruncher$setId * -1 + 48
new_ycruncher <- new_ycruncher[order(new_ycruncher$setId), ]
print(head(new_ycruncher))
View(pgbench)
pgbench$setId <- pgbench$setId * -1 + 48
pgbench <- pgbench[order(pgbench$setId), ]
print(head(pgbench))
#Now fix the vmids
pgbench$vmId <- new_iperf$vmId
new_sysbench$vmId <- new_iperf$vmId
new_ycruncher$vmId <- new_iperf$vmId
View(new_sysbench)
View(new_ycruncher)
#All data sets should have same dimensions
print(dim(new_iperf))
print(dim(pgbench))
print(dim(new_sysbench))
print(dim(new_ycruncher))
#Put all data into a dataframe
globalMerged = data.frame()
for (set in 1:48) {
for (vm in 1:set) {
a = new_iperf[new_iperf$setId == set & new_iperf$vmId == vm,]
b = new_sysbench[new_sysbench$setId == set & new_sysbench$vmId == vm,]
c = new_ycruncher[new_ycruncher$setId == set & new_ycruncher$vmId == vm,]
d = pgbench[pgbench$setId == set & pgbench$vmId == vm,]
merged = cbind(a["i_perf"],b["sysbench"],c["yCruncher"],d["pgbench"],rep.int(set, 3), rep.int(vm, 3))
globalMerged = rbind(globalMerged, merged)
}
}
View(globalMerged)
colnames(globalMerged)[colnames(globalMerged)=="rep.int(set, 3)"] <- set
colnames(globalMerged)[colnames(globalMerged)=="rep.int(set, 3)"] <- "set"
colnames(globalMerged)[colnames(globalMerged)=="48"] <- "set"
colnames(globalMerged)[colnames(globalMerged)=="rep.int(vm, 3)"] <- "vm"
#write it out as merged.csv.
write.csv(globalMerged,"./merged.csv",row.names=FALSE, col.names=FALSE)
#Clear workspace
rm(list=ls())
library(randomForest)
library(rpart)
wholeSet = read.csv("./merged.csv")
str(wholeSet)
# Loading the dplyr package
library(dplyr)
# Using sample_frac to create 70 - 30 slipt into test and train
train <- sample_frac(wholeSet, 0.9)
sample_id <- as.numeric(rownames(train)) # rownames() returns character so as.numeric
test <- wholeSet[-sample_id,]
formula = set~i_perf+sysbench+ycruncher+pgbench
modelRandomForest <- randomForest(
formula,
data=train)
print(modelRandomForest)
modelRandomForest <- randomForest(
formula,
data=train)
#Clear workspace
rm(list=ls())
wholeSet = read.csv("./merged.csv")
library(randomForest)
library(rpart)
str(wholeSet)
# Loading the dplyr package
library(dplyr)
# Using sample_frac to create 70 - 30 slipt into test and train
train <- sample_frac(wholeSet, 0.9)
sample_id <- as.numeric(rownames(train)) # rownames() returns character so as.numeric
test <- wholeSet[-sample_id,]
formula = set~iperf+sysbench+ycruncher+pgbench
modelRandomForest <- randomForest(
formula,
data=train)
print(modelRandomForest)
setwd("/home/ravschoo/ResourceContention/IaaSCloudResourceContention/modeldata/m5d")
#Clear workspace
rm(list=ls())
library(randomForest)
library(rpart)
set.seed(100)
wholeSet = read.csv("./merged.csv")
str(wholeSet)
# Loading the dplyr package
library(dplyr)
formula = setId~iperf+sysbench+ycruncher+pgbench
modelRandomForest <- randomForest(formula, data=wholeSet, ntree=2000)
print(modelRandomForest)
View(wholeSet)
formula = setId~iperf+sysbench+ycruncher+pgbench
modelRandomForest <- randomForest(formula, data=wholeSet, ntree=500)
formula = set~iperf+sysbench+ycruncher+pgbench
modelRandomForest <- randomForest(formula, data=wholeSet, ntree=500)
formula = setId~iperf+sysbench+ycruncher+pgbench
modelRandomForest <- randomForest(formula, data=wholeSet, ntree=500)
str(wholeSet)
modelRandomForest <- randomForest(formula, data=wholeSet, ntree=500, na.action=na.exclude)
#Clear workspace
rm(list=ls())
library(randomForest)
library(rpart)
set.seed(100)
wholeSet = read.csv("./merged.csv")
#Convert to mbs, only if they are in gbs
wholeSet$iperf <- wholeSet$iperf * 1000
str(wholeSet)
# Loading the dplyr package
library(dplyr)
formula = setId~iperf+sysbench+ycruncher+pgbench
modelRandomForest <- randomForest(formula, data=wholeSet, ntree=500, na.action=na.exclude)
print(modelRandomForest)
modelRandomForest <- randomForest(formula, data=wholeSet, ntree=2000, na.action=na.exclude)
print(modelRandomForest)
# Importance of each predictor.
print(importance(modelRandomForest,type = 2))
saveRDS(modelRandomForest, "./modelRandomForest.rds")
setwd("/home/ravschoo/ResourceContention/IaaSCloudResourceContention/modeldata/m5d/DedicatedHost/")
#Clear workspace
rm(list=ls())
#load Open Cloud data
set.seed(100)
wholeSet = read.csv("./Aggregate_Summary_Dedicated_Host_11-16-2019.csv")
View(wholeSet)
# load the model
super_model <- readRDS("modelRandomForest.rds")
print(super_model)
predictions <- predict(super_model, wholeSet)
max(predictions)
min(predictions)
mean(predictions)
sd(predictions)
#calculate the rmse
predictions_rmse <- rmse(wholeSet$setId, rounded_predictions)
#calculate the rmse
library("modelMetrics")
??modelMetrics
#calculate the rmse
library("ModelMetrics")
predictions_rmse <- rmse(wholeSet$setId, predictions)
predictions_rmse
plot(predictions, wholeSet$setId, xlab="predicted", ylab="actual")
abline(a=0,b=1)
write.csv(predictions, "./predictions.csv")
#Graph error
par(mfrow=c(1,1))
plot(super_model)
plot(predictions, wholeSet$setId, xlab="predicted", ylab="actual", col="blue")
abline(a=0,b=1)
setwd("/home/ravschoo/ResourceContention/IaaSCloudResourceContention/modeldata/m5d/OpenCloud/")
#Clear workspace
rm(list=ls())
#load Open Cloud data
set.seed(100)
wholeSet = read.csv("./merged.csv")
# load the model
super_model <- readRDS("modelRandomForest.rds")
print(super_model)
predictions <- predict(super_model, wholeSet)
max(predictions)
min(predictions)
mean(predictions)
sd(predictions)
write.csv(predictions, "./predictions_openCloud.csv")
View(wholeSet)
View(wholeSet)
wholeSet$iperf <- wholeSet$iperf
setwd("/home/ravschoo/ResourceContention/IaaSCloudResourceContention/modeldata/m5d/OpenCloud/")
#Clear workspace
rm(list=ls())
#load Open Cloud data
set.seed(100)
wholeSet = read.csv("./merged.csv")
wholeSet$iperf <- wholeSet$iperf * 1000
# load the model
super_model <- readRDS("modelRandomForest.rds")
print(super_model)
predictions <- predict(super_model, wholeSet)
predictions
max(predictions)
min(predictions)
mean(predictions)
sd(predictions)
write.csv(predictions, "./predictions_openCloud.csv")
setwd("/home/ravschoo/ResourceContention/IaaSCloudResourceContention/modeldata/m5d/DedicatedHost/")
#Clear workspace
rm(list=ls())
set.seed(100)
wholeSet = read.csv("./Aggregate_Summary_Dedicated_Host_11-16-2019.csv")
library(nnet)
formula = set~iperf+sysbench+ycruncher+pgbench
View(wholeSet)
View(wholeSet)
formula = setId~iperf+sysbench+ycruncher+pgbench
multinomModel <- multinom(formula, data=wholeSet) # multinom Model
summary (multinomModel) # model summary
saveRDS(modelRandomForest, "./modelMultLogReg.rds")
saveRDS(multinomModel, "./multinomModel.rds")
setwd("/home/ravschoo/ResourceContention/IaaSCloudResourceContention/modeldata/m5d/DedicatedHost/")
#Clear workspace
rm(list=ls())
setwd("/home/ravschoo/ResourceContention/IaaSCloudResourceContention/modeldata/m5d/")
#Clear workspace
rm(list=ls())
set.seed(100)
wholeSet = read.csv("./merged.csv")
library(nnet)
formula = setId~iperf+sysbench+ycruncher+pgbench
multinomModel <- multinom(formula, data=wholeSet) # multinom Model
#If iperf is in gbs turn to mbs
wholeSet$iperf <- wholeSet$iperf * 1000
# load the model
super_model <- readRDS("modelRandomForest.rds")
setwd("/home/ravschoo/ResourceContention/IaaSCloudResourceContention/modeldata/m5d/")
#Clear workspace
rm(list=ls())
set.seed(100)
wholeSet = read.csv("./merged.csv")
#If iperf is in gbs turn to mbs
wholeSet$iperf <- wholeSet$iperf * 1000
library(nnet)
formula = setId~iperf+sysbench+ycruncher+pgbench
multinomModel <- multinom(formula, data=wholeSet) # multinom Model
summary (multinomModel) # model summary
formula = setId~sysbench+ycruncher+pgbench
multinomModel <- multinom(formula, data=wholeSet) # multinom Model
summary (multinomModel) # model summary
formula = setId~iperf+sysbench+ycruncher
multinomModel <- multinom(formula, data=wholeSet) # multinom Model
summary (multinomModel) # model summary
formula = setId~iperf+sysbench+ycruncher+pgbench
multinomModel <- multinom(formula, data=wholeSet) # multinom Model
summary (multinomModel) # model summary
saveRDS(multinomModel, "./multinomModel.rds")
setwd("/home/ravschoo/ResourceContention/IaaSCloudResourceContention/modeldata/m5d/DedicatedHost/")
#Clear workspace
rm(list=ls())
#load Open Cloud data
set.seed(100)
wholeSet = read.csv("./Aggregate_Summary_Dedicated_Host_11-16-2019.csv")
# load the model
super_model <- readRDS("multinomModel.rds")
print(super_model)
predictions <- predict(super_model, wholeSet)
max(predictions)
predictions
predicted_scores <- predict (multinomModel, wholeSet, "probs")
predicted_scores <- predict (super_model, wholeSet, "probs")
predicted_scores
predicted_class <- predict (super_model, wholeSet)
table(predicted_class, wholeSet$setId)
o
plot(x = wholeSet$setId , y = predicted_class,col="blue",pch=19,xlab="set observed",ylab="set predicted")
axis(1,1:48,1:48,cex.axis=0.8)
axis(2,1:148,1:48,cex.axis=0.8)
par(new=TRUE)
lines(x = range(1:48) , y = range(1:48),col="red")
legend("topright",legend=c("observed value","predicted value"),pch=19, col=c("red","blue"))
predictions_rmse <- rmse(wholeSet$setId, predictions)
#calculate the rmse
library("ModelMetrics")
predictions_rmse <- rmse(wholeSet$setId, predictions)
predictions_rmse
setwd("/home/ravschoo/ResourceContention/IaaSCloudResourceContention/modeldata/m5d/DedicatedHost/")
#Clear workspace
rm(list=ls())
#load Open Cloud data
set.seed(100)
wholeSet = read.csv("./merged_11-16-2019 .csv")
# load the model
super_model <- readRDS("modelRandomForest.rds")
print(super_model)
predictions <- predict(super_model, wholeSet)
predictions
max(predictions)
min(predictions)
mean(predictions)
sd(predictions)
#calculate the rmse
library("ModelMetrics")
predictions_rmse <- rmse(wholeSet$setId, predictions)
predictions_rmse
plot(predictions, wholeSet$setId, xlab="predicted", ylab="actual", col="blue")
abline(a=0,b=1)
max(predictions)
min(predictions)
mean(predictions)
sd(predictions)
wholeSet = read.csv("./merged.csv")
setwd("/home/ravschoo/ResourceContention/IaaSCloudResourceContention/modeldata/m5d/OpenCloud/")
library("randomForest")
#load Open Cloud data
set.seed(100)
wholeSet = read.csv("./merged.csv")
wholeSet$iperf <- wholeSet$iperf * 1000
print(super_model)
max(predictions)
min(predictions)
mean(predictions)
sd(predictions)
predictions_open <- predict(super_model, wholeSet)
max(predictions_open)
min(predictions_open)
mean(predictions_open)
sd(predictions_open)
#calculate the rmse
library("ModelMetrics")
predictions_rmse <- rmse(wholeSet$setId, predictions)
predictions_rmse
